{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {"provenance": [], "gpuType": "None"},
  "kernelspec": {"name": "python3", "display_name": "Python 3"},
  "language_info": {"name": "python"},
  "accelerator": "None"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab 1/3 — Daten-Aufbereitung\n",
    "\n",
    "**Rolle in der 3-Saeulen-Architektur:** KI-Labor (Daten-Vorbereitung)\n",
    "\n",
    "**Dieses Notebook tut NUR:**\n",
    "- BTC/USDT OHLCV-Daten von Binance oder Yahoo Finance laden\n",
    "- Features berechnen (FeatureEngine)\n",
    "- Scaler fitten und speichern\n",
    "- Alles auf Google Drive sichern fuer Notebook 2 und 3\n",
    "\n",
    "**Kein GPU noetig! Wähle bei Runtime: `None` (CPU)**\n",
    "\n",
    "---\n",
    "**Warum 3 getrennte Notebooks?**\n",
    "Ein einzelnes Notebook das alles macht (Daten + Evolution + PPO) verbraucht nach\n",
    "~1h den gesamten RAM (12 GB). Die Daten bleiben im RAM waehrend das Training laeuft.\n",
    "Mit 3 Notebooks wird jede Aufgabe in einer frischen Session gestartet - kein Altlast-RAM.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 1: Repo klonen & Dependencies installieren"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "PROJECT_DIR = '/content/BITCOIN4Traders'\n",
    "REPO_URL    = 'https://github.com/juancarlosrial76-code/BITCOIN4Traders.git'\n",
    "\n",
    "if os.path.exists(PROJECT_DIR) and not os.path.exists(f'{PROJECT_DIR}/.git'):\n",
    "    shutil.rmtree(PROJECT_DIR)\n",
    "\n",
    "if not os.path.exists(PROJECT_DIR):\n",
    "    !git clone {REPO_URL} {PROJECT_DIR} --quiet\n",
    "    print('Repo geklont.')\n",
    "else:\n",
    "    !git -C {PROJECT_DIR} pull --quiet\n",
    "    print('Repo aktualisiert.')\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "print(f'Verzeichnis: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Nur Daten-Dependencies - kein torch, kein gymnasium\n",
    "# Schneller + weniger RAM als full install\n",
    "!pip install -q ccxt loguru pyarrow pandas numpy ta yfinance numba joblib pyyaml scikit-learn python-dotenv tqdm\n",
    "print('Dependencies installiert.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 2: Google Drive mounten"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_DIR   = '/content/drive/MyDrive/BITCOIN4Traders'\n",
    "DRIVE_DATA  = f'{DRIVE_DIR}/data'\n",
    "DRIVE_PROC  = f'{DRIVE_DIR}/processed'\n",
    "\n",
    "import os\n",
    "for d in [DRIVE_DIR, DRIVE_DATA, DRIVE_PROC]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f'Drive bereit: {DRIVE_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 3: Konfiguration"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== EINSTELLUNGEN =====\n",
    "SYMBOL      = 'BTC/USDT'\n",
    "TIMEFRAME   = '1h'\n",
    "START_DATE  = '2021-01-01'   # Mehr Daten = besser aber mehr RAM\n",
    "END_DATE    = None            # None = bis heute\n",
    "\n",
    "# Datentyp: float32 spart 50% RAM vs float64\n",
    "DTYPE       = 'float32'\n",
    "\n",
    "# Max Candles in RAM halten (Colab: 12 GB Limit)\n",
    "# 1h-Candles seit 2021 = ~35.000 Bars = ~50 MB als float32 - passt\n",
    "MAX_CANDLES = 40_000\n",
    "\n",
    "print(f'Symbol:     {SYMBOL}')\n",
    "print(f'Zeitraum:   {START_DATE} bis {END_DATE or \"heute\"}')\n",
    "print(f'Max Bars:   {MAX_CANDLES:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 4: Daten laden (Binance oder Yahoo Finance Fallback)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "\n",
    "sys.path.insert(0, '/content/BITCOIN4Traders')\n",
    "sys.path.insert(0, '/content/BITCOIN4Traders/src')\n",
    "\n",
    "CACHE_FILE = Path(DRIVE_DATA) / 'BTC_USDT_1h_raw.parquet'\n",
    "\n",
    "# ── Bereits auf Drive gecacht? ──────────────────────────────────────\n",
    "if CACHE_FILE.exists():\n",
    "    logger.info(f'Lade gecachte Rohdaten von Drive: {CACHE_FILE}')\n",
    "    price_data = pd.read_parquet(CACHE_FILE)\n",
    "    # Auf MAX_CANDLES begrenzen (neueste Daten)\n",
    "    if len(price_data) > MAX_CANDLES:\n",
    "        price_data = price_data.iloc[-MAX_CANDLES:]\n",
    "    logger.success(f'Gecachte Daten geladen: {len(price_data):,} Bars')\n",
    "\n",
    "else:\n",
    "    price_data = None\n",
    "\n",
    "    # ── Versuch 1: Binance via CCXT ─────────────────────────────────\n",
    "    if price_data is None:\n",
    "        try:\n",
    "            import ccxt\n",
    "            exchange = ccxt.binance({'enableRateLimit': True})\n",
    "            logger.info('Lade von Binance...')\n",
    "\n",
    "            since_ms = exchange.parse8601(f'{START_DATE}T00:00:00Z')\n",
    "            all_ohlcv = []\n",
    "            limit = 1000\n",
    "\n",
    "            while True:\n",
    "                ohlcv = exchange.fetch_ohlcv(SYMBOL, TIMEFRAME, since=since_ms, limit=limit)\n",
    "                if not ohlcv:\n",
    "                    break\n",
    "                all_ohlcv.extend(ohlcv)\n",
    "                since_ms = ohlcv[-1][0] + 1\n",
    "                if len(ohlcv) < limit:\n",
    "                    break\n",
    "                import time; time.sleep(0.3)  # Rate-Limit\n",
    "\n",
    "            price_data = pd.DataFrame(\n",
    "                all_ohlcv,\n",
    "                columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "            )\n",
    "            price_data['timestamp'] = pd.to_datetime(price_data['timestamp'], unit='ms')\n",
    "            price_data = price_data.set_index('timestamp').sort_index()\n",
    "            price_data = price_data.astype(DTYPE)\n",
    "            logger.success(f'Binance: {len(price_data):,} Bars geladen')\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f'Binance fehlgeschlagen: {e}')\n",
    "\n",
    "    # ── Versuch 2: Yahoo Finance (Fallback, kein Geo-Block) ─────────\n",
    "    if price_data is None:\n",
    "        try:\n",
    "            import yfinance as yf\n",
    "            yf_symbol = 'BTC-USD'\n",
    "            logger.info(f'Lade {yf_symbol} von Yahoo Finance...')\n",
    "            df = yf.download(yf_symbol, start=START_DATE, end=END_DATE,\n",
    "                             interval='1h', progress=False, auto_adjust=True)\n",
    "            df.columns = [c.lower() for c in df.columns]\n",
    "            df = df[['open', 'high', 'low', 'close', 'volume']]\n",
    "            df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "            df = df.astype(DTYPE)\n",
    "            price_data = df\n",
    "            logger.success(f'Yahoo Finance: {len(price_data):,} Bars geladen')\n",
    "        except Exception as e:\n",
    "            logger.error(f'Yahoo Finance fehlgeschlagen: {e}')\n",
    "\n",
    "    if price_data is None:\n",
    "        raise RuntimeError('Keine Daten geladen! Netzwerk pruefen.')\n",
    "\n",
    "    # Auf MAX_CANDLES begrenzen\n",
    "    if len(price_data) > MAX_CANDLES:\n",
    "        price_data = price_data.iloc[-MAX_CANDLES:]\n",
    "\n",
    "    # Auf Drive cachen\n",
    "    logger.info(f'Speichere Rohdaten auf Drive: {CACHE_FILE}')\n",
    "    price_data.to_parquet(CACHE_FILE, engine='pyarrow', compression='snappy')\n",
    "\n",
    "# NaN entfernen\n",
    "price_data = price_data.dropna()\n",
    "\n",
    "# RAM-Check\n",
    "mem_mb = price_data.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f'\\nDaten: {len(price_data):,} Bars | RAM: {mem_mb:.1f} MB | dtype: {price_data.dtypes[0]}')\n",
    "print(f'Zeitraum: {price_data.index[0]} bis {price_data.index[-1]}')\n",
    "print(price_data.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 5: Features berechnen & Scaler speichern"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from features.feature_engine import FeatureEngine, FeatureConfig\n",
    "\n",
    "PROC_DIR = Path(DRIVE_PROC)\n",
    "\n",
    "# ── Split: 70% Train, 15% Val, 15% Test ─────────────────────────────\n",
    "n         = len(price_data)\n",
    "train_end = int(n * 0.70)\n",
    "val_end   = int(n * 0.85)\n",
    "\n",
    "train_raw = price_data.iloc[:train_end]\n",
    "val_raw   = price_data.iloc[train_end:val_end]\n",
    "test_raw  = price_data.iloc[val_end:]\n",
    "\n",
    "logger.info(f'Split: Train={len(train_raw):,} | Val={len(val_raw):,} | Test={len(test_raw):,}')\n",
    "\n",
    "# ── Feature Engineering ─────────────────────────────────────────────\n",
    "feat_cfg = FeatureConfig(\n",
    "    volatility_window=20,\n",
    "    ou_window=20,\n",
    "    rolling_mean_window=20,\n",
    "    use_log_returns=True,\n",
    "    scaler_type='standard',\n",
    "    save_scaler=True,\n",
    "    scaler_path=PROC_DIR,         # Scaler wird auf Drive gespeichert\n",
    "    dropna_strategy='rolling',\n",
    "    min_valid_rows=500,\n",
    ")\n",
    "\n",
    "engine = FeatureEngine(feat_cfg)\n",
    "\n",
    "logger.info('Fit FeatureEngine auf Trainingsdaten (KEIN Leakage)...')\n",
    "train_feat = engine.fit_transform(train_raw)\n",
    "val_feat   = engine.transform(val_raw)\n",
    "test_feat  = engine.transform(test_raw)\n",
    "\n",
    "# Indizes angleichen\n",
    "idx_train = train_raw.index.intersection(train_feat.index)\n",
    "idx_val   = val_raw.index.intersection(val_feat.index)\n",
    "idx_test  = test_raw.index.intersection(test_feat.index)\n",
    "\n",
    "logger.success(f'Features: {train_feat.shape[1]} Spalten | Train-Samples: {len(idx_train):,}')\n",
    "\n",
    "# ── Auf Drive speichern (komprimiert float32) ───────────────────────\n",
    "def save_split(price, feat, idx, name):\n",
    "    p_path = PROC_DIR / f'{name}_price.parquet'\n",
    "    f_path = PROC_DIR / f'{name}_feat.parquet'\n",
    "    price.loc[idx].astype('float32').to_parquet(p_path, compression='snappy')\n",
    "    feat.loc[idx].astype('float32').to_parquet(f_path, compression='snappy')\n",
    "    size_mb = (p_path.stat().st_size + f_path.stat().st_size) / 1024**2\n",
    "    logger.success(f'Gespeichert: {name} ({size_mb:.1f} MB)')\n",
    "\n",
    "save_split(train_raw, train_feat, idx_train, 'train')\n",
    "save_split(val_raw,   val_feat,   idx_val,   'val')\n",
    "save_split(test_raw,  test_feat,  idx_test,  'test')\n",
    "\n",
    "# ── RAM freigeben ───────────────────────────────────────────────────\n",
    "del train_feat, val_feat, test_feat, train_raw, val_raw, test_raw, price_data\n",
    "gc.collect()\n",
    "\n",
    "print('\\nDaten-Aufbereitung abgeschlossen!')\n",
    "print(f'Dateien auf Drive: {PROC_DIR}')\n",
    "print('Weiter mit: Colab_2_Evolution.ipynb oder Colab_3_PPO_Training.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 6: Ergebnis pruefen\n",
    "\n",
    "Zeigt alle gespeicherten Dateien auf Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print('=== Gespeicherte Dateien auf Drive ===')\n",
    "total = 0\n",
    "for f in sorted(Path(DRIVE_PROC).iterdir()):\n",
    "    mb = f.stat().st_size / 1024**2\n",
    "    total += mb\n",
    "    print(f'  {f.name:35s}  {mb:.1f} MB')\n",
    "print(f'\\nGesamt: {total:.1f} MB')\n",
    "print('\\nNotebook 1 fertig. Starte jetzt Notebook 2 oder 3.')"
   ]
  }
 ]
}
