{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {"provenance": [], "gpuType": "None"},
  "kernelspec": {"name": "python3", "display_name": "Python 3"},
  "language_info": {"name": "python"},
  "accelerator": "None"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab 1/3 — Daten-Aufbereitung\n",
    "\n",
    "**Rolle in der 3-Saeulen-Architektur:** KI-Labor (Daten-Vorbereitung)\n",
    "\n",
    "**Dieses Notebook tut NUR:**\n",
    "- BTC/USDT OHLCV-Daten von Binance oder Yahoo Finance laden\n",
    "- Features berechnen (FeatureEngine)\n",
    "- Scaler fitten und speichern\n",
    "- Alles auf Google Drive sichern fuer Notebook 2 und 3\n",
    "\n",
    "**Kein GPU noetig! Wähle bei Runtime: `None` (CPU)**\n",
    "\n",
    "---\n",
    "**Warum 3 getrennte Notebooks?**\n",
    "Ein einzelnes Notebook das alles macht (Daten + Evolution + PPO) verbraucht nach\n",
    "~1h den gesamten RAM (12 GB). Die Daten bleiben im RAM waehrend das Training laeuft.\n",
    "Mit 3 Notebooks wird jede Aufgabe in einer frischen Session gestartet - kein Altlast-RAM.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 1: Repo klonen & Dependencies installieren"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "PROJECT_DIR = '/content/BITCOIN4Traders'\n",
    "REPO_URL    = 'https://github.com/juancarlosrial76-code/BITCOIN4Traders.git'\n",
    "\n",
    "if os.path.exists(PROJECT_DIR) and not os.path.exists(f'{PROJECT_DIR}/.git'):\n",
    "    shutil.rmtree(PROJECT_DIR)\n",
    "\n",
    "if not os.path.exists(PROJECT_DIR):\n",
    "    !git clone {REPO_URL} {PROJECT_DIR} --quiet\n",
    "    print('Repo geklont.')\n",
    "else:\n",
    "    !git -C {PROJECT_DIR} pull --quiet\n",
    "    print('Repo aktualisiert.')\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "print(f'Verzeichnis: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Nur Daten-Dependencies - kein torch, kein gymnasium\n",
    "# Schneller + weniger RAM als full install\n",
    "!pip install -q ccxt loguru pyarrow pandas numpy ta yfinance numba joblib pyyaml scikit-learn python-dotenv tqdm\n",
    "print('Dependencies installiert.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 2: Google Drive mounten"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_DIR   = '/content/drive/MyDrive/BITCOIN4Traders'\n",
    "DRIVE_DATA  = f'{DRIVE_DIR}/data'\n",
    "DRIVE_PROC  = f'{DRIVE_DIR}/processed'\n",
    "\n",
    "import os\n",
    "for d in [DRIVE_DIR, DRIVE_DATA, DRIVE_PROC]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f'Drive bereit: {DRIVE_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 3: Konfiguration"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
     "from datetime import datetime, timedelta\n",
     "\n",
     "# ===== EINSTELLUNGEN =====\n",
     "SYMBOL      = 'BTC/USDT'\n",
     "TIMEFRAME   = '1h'\n",
     "END_DATE    = None            # None = bis heute\n",
     "\n",
     "# Datentyp: float32 spart 50% RAM vs float64\n",
     "DTYPE       = 'float32'\n",
     "\n",
     "# Max Candles in RAM halten (Colab: 12 GB Limit)\n",
     "MAX_CANDLES = 17_000  # ~2 Jahre a 1h = 17.520 Bars\n",
     "\n",
     "# Yahoo Finance erlaubt fuer 1h-Daten maximal 729 Tage zurueck.\n",
     "# Wir rechnen das automatisch aus - kein manuelles Anpassen noetig.\n",
     "YF_MAX_DAYS = 729\n",
     "YF_START    = (datetime.utcnow() - timedelta(days=YF_MAX_DAYS)).strftime('%Y-%m-%d')\n",
     "\n",
     "# Binance/KuCoin koennen weiter zurueck (seit 2020), aber Colab-IPs\n",
     "# werden von Binance US geblockt (451). KuCoin ist der zuverlaessigste Fallback.\n",
     "CCXT_START  = '2022-01-01'  # 3 Jahre - genuegt fuer robustes Training\n",
     "\n",
     "print(f'Symbol:          {SYMBOL}')\n",
     "print(f'CCXT Start:      {CCXT_START}')\n",
     "print(f'YF Start (auto): {YF_START}  (max {YF_MAX_DAYS} Tage fuer 1h-Daten)')\n",
     "print(f'Max Bars:        {MAX_CANDLES:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 4: Daten laden (Binance oder Yahoo Finance Fallback)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
     "import sys, gc, time\n",
     "import pandas as pd\n",
     "import numpy as np\n",
     "from pathlib import Path\n",
     "from loguru import logger\n",
     "\n",
     "sys.path.insert(0, '/content/BITCOIN4Traders')\n",
     "sys.path.insert(0, '/content/BITCOIN4Traders/src')\n",
     "\n",
     "CACHE_FILE = Path(DRIVE_DATA) / 'BTC_USDT_1h_raw.parquet'\n",
     "\n",
     "# ─────────────────────────────────────────────────────────────────────\n",
     "# Hilfsfunktion: CCXT OHLCV → sauberer DataFrame\n",
     "# ─────────────────────────────────────────────────────────────────────\n",
     "def ccxt_to_df(ohlcv_list, dtype='float32'):\n",
     "    df = pd.DataFrame(ohlcv_list, columns=['timestamp','open','high','low','close','volume'])\n",
     "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
     "    df = df.set_index('timestamp').sort_index()\n",
     "    df = df[~df.index.duplicated(keep='last')]\n",
     "    return df.astype(dtype)\n",
     "\n",
     "def fetch_ccxt(exchange_id, symbol, timeframe, start_date, dtype='float32'):\n",
     "    \"\"\"Laedt OHLCV via CCXT mit Paginierung. Gibt None bei Fehler zurueck.\"\"\"\n",
     "    import ccxt\n",
     "    ex = getattr(ccxt, exchange_id)({'enableRateLimit': True})\n",
     "    since_ms = ex.parse8601(f'{start_date}T00:00:00Z')\n",
     "    all_ohlcv, limit = [], 1000\n",
     "    logger.info(f'Lade von {exchange_id} ({symbol} {timeframe} ab {start_date})...')\n",
     "    while True:\n",
     "        batch = ex.fetch_ohlcv(symbol, timeframe, since=since_ms, limit=limit)\n",
     "        if not batch:\n",
     "            break\n",
     "        all_ohlcv.extend(batch)\n",
     "        since_ms = batch[-1][0] + 1\n",
     "        if len(batch) < limit:\n",
     "            break\n",
     "        time.sleep(0.25)\n",
     "    if not all_ohlcv:\n",
     "        raise ValueError(f'Keine Daten von {exchange_id}')\n",
     "    df = ccxt_to_df(all_ohlcv, dtype)\n",
     "    logger.success(f'{exchange_id}: {len(df):,} Bars geladen')\n",
     "    return df\n",
     "\n",
     "def fetch_yfinance(symbol_yf, start_date, dtype='float32'):\n",
     "    \"\"\"Laedt von Yahoo Finance. Behebt Multi-Level-Columns Bug von yfinance.\"\"\"\n",
     "    import yfinance as yf\n",
     "    logger.info(f'Lade {symbol_yf} von Yahoo Finance (ab {start_date})...')\n",
     "    df = yf.download(symbol_yf, start=start_date, interval='1h',\n",
     "                     progress=False, auto_adjust=True)\n",
     "    if df.empty:\n",
     "        raise ValueError(f'Keine Daten von Yahoo Finance fuer {symbol_yf}')\n",
     "    # FIX: yfinance gibt MultiIndex-Spalten zurueck (z.B. ('Close','BTC-USD')).\n",
     "    # df.columns = [c.lower() for c in df.columns] wirft dann\n",
     "    # 'tuple object has no attribute lower'.\n",
     "    # Loesung: Spalten auf erste Ebene reduzieren, dann lower().\n",
     "    if isinstance(df.columns, pd.MultiIndex):\n",
     "        df.columns = df.columns.get_level_values(0)\n",
     "    df.columns = [str(c).lower() for c in df.columns]\n",
     "    df = df[['open', 'high', 'low', 'close', 'volume']]\n",
     "    # Timezone entfernen (tz-aware Index -> tz-naive)\n",
     "    if hasattr(df.index, 'tz') and df.index.tz is not None:\n",
     "        df.index = df.index.tz_localize(None)\n",
     "    df.index.name = 'timestamp'\n",
     "    df = df.astype(dtype)\n",
     "    logger.success(f'Yahoo Finance: {len(df):,} Bars geladen')\n",
     "    return df\n",
     "\n",
     "# ─────────────────────────────────────────────────────────────────────\n",
     "# Daten laden: Cache → KuCoin → Bybit → Yahoo Finance\n",
     "# ─────────────────────────────────────────────────────────────────────\n",
     "if CACHE_FILE.exists():\n",
     "    logger.info(f'Lade gecachte Daten von Drive...')\n",
     "    price_data = pd.read_parquet(CACHE_FILE)\n",
     "    logger.success(f'Cache: {len(price_data):,} Bars')\n",
     "\n",
     "else:\n",
     "    price_data = None\n",
     "\n",
     "    # Versuch 1: KuCoin (kein Geo-Block, kein US-Limit)\n",
     "    if price_data is None:\n",
     "        try:\n",
     "            price_data = fetch_ccxt('kucoin', 'BTC/USDT', TIMEFRAME, CCXT_START, DTYPE)\n",
     "        except Exception as e:\n",
     "            logger.warning(f'KuCoin fehlgeschlagen: {e}')\n",
     "\n",
     "    # Versuch 2: Bybit (grosser Exchange, kein Geo-Block)\n",
     "    if price_data is None:\n",
     "        try:\n",
     "            price_data = fetch_ccxt('bybit', 'BTC/USDT', TIMEFRAME, CCXT_START, DTYPE)\n",
     "        except Exception as e:\n",
     "            logger.warning(f'Bybit fehlgeschlagen: {e}')\n",
     "\n",
     "    # Versuch 3: OKX\n",
     "    if price_data is None:\n",
     "        try:\n",
     "            price_data = fetch_ccxt('okx', 'BTC/USDT', TIMEFRAME, CCXT_START, DTYPE)\n",
     "        except Exception as e:\n",
     "            logger.warning(f'OKX fehlgeschlagen: {e}')\n",
     "\n",
     "    # Versuch 4: Yahoo Finance (max 729 Tage fuer 1h, kein Login)\n",
     "    # YF_START ist bereits auf 729 Tage begrenzt (aus Schritt 3 berechnet)\n",
     "    if price_data is None:\n",
     "        try:\n",
     "            price_data = fetch_yfinance('BTC-USD', YF_START, DTYPE)\n",
     "        except Exception as e:\n",
     "            logger.error(f'Yahoo Finance fehlgeschlagen: {e}')\n",
     "\n",
     "    if price_data is None:\n",
     "        raise RuntimeError(\n",
     "            'Alle Datenquellen fehlgeschlagen!\\n'\n",
     "            'KuCoin / Bybit / OKX / Yahoo Finance konnten keine Daten liefern.\\n'\n",
     "            'Bitte Runtime neu starten und erneut versuchen.'\n",
     "        )\n",
     "\n",
     "    # Auf MAX_CANDLES begrenzen (neueste Bars)\n",
     "    if len(price_data) > MAX_CANDLES:\n",
     "        price_data = price_data.iloc[-MAX_CANDLES:]\n",
     "\n",
     "    # Auf Drive cachen\n",
     "    logger.info(f'Speichere auf Drive: {CACHE_FILE}')\n",
     "    price_data.to_parquet(CACHE_FILE, engine='pyarrow', compression='snappy')\n",
     "\n",
     "# NaN und Nullwerte entfernen\n",
     "price_data = price_data.replace(0, np.nan).dropna()\n",
     "\n",
     "# Auf MAX_CANDLES begrenzen auch wenn von Cache\n",
     "if len(price_data) > MAX_CANDLES:\n",
     "    price_data = price_data.iloc[-MAX_CANDLES:]\n",
     "\n",
     "# RAM-Check\n",
     "mem_mb = price_data.memory_usage(deep=True).sum() / 1024**2\n",
     "print(f'\\nDaten: {len(price_data):,} Bars | RAM: {mem_mb:.1f} MB | dtype: {price_data.dtypes[0]}')\n",
     "print(f'Zeitraum: {price_data.index[0]} bis {price_data.index[-1]}')\n",
     "print(price_data.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Schritt 5: Features berechnen & Scaler speichern"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from features.feature_engine import FeatureEngine, FeatureConfig\n",
    "\n",
    "PROC_DIR = Path(DRIVE_PROC)\n",
    "\n",
    "# ── Split: 70% Train, 15% Val, 15% Test ─────────────────────────────\n",
    "n         = len(price_data)\n",
    "train_end = int(n * 0.70)\n",
    "val_end   = int(n * 0.85)\n",
    "\n",
    "train_raw = price_data.iloc[:train_end]\n",
    "val_raw   = price_data.iloc[train_end:val_end]\n",
    "test_raw  = price_data.iloc[val_end:]\n",
    "\n",
    "logger.info(f'Split: Train={len(train_raw):,} | Val={len(val_raw):,} | Test={len(test_raw):,}')\n",
    "\n",
    "# ── Feature Engineering ─────────────────────────────────────────────\n",
    "feat_cfg = FeatureConfig(\n",
    "    volatility_window=20,\n",
    "    ou_window=20,\n",
    "    rolling_mean_window=20,\n",
    "    use_log_returns=True,\n",
    "    scaler_type='standard',\n",
    "    save_scaler=True,\n",
    "    scaler_path=PROC_DIR,         # Scaler wird auf Drive gespeichert\n",
    "    dropna_strategy='rolling',\n",
    "    min_valid_rows=500,\n",
    ")\n",
    "\n",
    "engine = FeatureEngine(feat_cfg)\n",
    "\n",
    "logger.info('Fit FeatureEngine auf Trainingsdaten (KEIN Leakage)...')\n",
    "train_feat = engine.fit_transform(train_raw)\n",
    "val_feat   = engine.transform(val_raw)\n",
    "test_feat  = engine.transform(test_raw)\n",
    "\n",
    "# Indizes angleichen\n",
    "idx_train = train_raw.index.intersection(train_feat.index)\n",
    "idx_val   = val_raw.index.intersection(val_feat.index)\n",
    "idx_test  = test_raw.index.intersection(test_feat.index)\n",
    "\n",
    "logger.success(f'Features: {train_feat.shape[1]} Spalten | Train-Samples: {len(idx_train):,}')\n",
    "\n",
    "# ── Auf Drive speichern (komprimiert float32) ───────────────────────\n",
    "def save_split(price, feat, idx, name):\n",
    "    p_path = PROC_DIR / f'{name}_price.parquet'\n",
    "    f_path = PROC_DIR / f'{name}_feat.parquet'\n",
    "    price.loc[idx].astype('float32').to_parquet(p_path, compression='snappy')\n",
    "    feat.loc[idx].astype('float32').to_parquet(f_path, compression='snappy')\n",
    "    size_mb = (p_path.stat().st_size + f_path.stat().st_size) / 1024**2\n",
    "    logger.success(f'Gespeichert: {name} ({size_mb:.1f} MB)')\n",
    "\n",
    "save_split(train_raw, train_feat, idx_train, 'train')\n",
    "save_split(val_raw,   val_feat,   idx_val,   'val')\n",
    "save_split(test_raw,  test_feat,  idx_test,  'test')\n",
    "\n",
    "# ── RAM freigeben ───────────────────────────────────────────────────\n",
    "del train_feat, val_feat, test_feat, train_raw, val_raw, test_raw, price_data\n",
    "gc.collect()\n",
    "\n",
    "print('\\nDaten-Aufbereitung abgeschlossen!')\n",
    "print(f'Dateien auf Drive: {PROC_DIR}')\n",
    "print('Weiter mit: Colab_2_Evolution.ipynb oder Colab_3_PPO_Training.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 6: Ergebnis pruefen\n",
    "\n",
    "Zeigt alle gespeicherten Dateien auf Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print('=== Gespeicherte Dateien auf Drive ===')\n",
    "total = 0\n",
    "for f in sorted(Path(DRIVE_PROC).iterdir()):\n",
    "    mb = f.stat().st_size / 1024**2\n",
    "    total += mb\n",
    "    print(f'  {f.name:35s}  {mb:.1f} MB')\n",
    "print(f'\\nGesamt: {total:.1f} MB')\n",
    "print('\\nNotebook 1 fertig. Starte jetzt Notebook 2 oder 3.')"
   ]
  }
 ]
}
