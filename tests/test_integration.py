"""
Integration Tests
=================

End-to-end tests that verify the entire system works together.
Tests the complete data flow from loading to training.
"""

import pytest
import numpy as np
import pandas as pd
from pathlib import Path

from features.feature_engine import FeatureEngine, FeatureConfig
from environment.config_integrated_env import ConfigIntegratedTradingEnv
from environment.config_system import EnvironmentConfig
from agents.ppo_agent import PPOAgent, PPOConfig
from training.adversarial_trainer import AdversarialTrainer, AdversarialConfig
from risk.risk_manager import RiskManager, RiskConfig


class MockExchangeDataLoader:
    """Mock data loader that simulates exchange data."""

    def __init__(self):
        np.random.seed(42)
        n_points = 1000
        self.dates = pd.date_range("2023-01-01", periods=n_points, freq="1H")

        # Generate realistic price data with trend
        trend = np.linspace(0, 5000, n_points)  # Upward drift over time
        noise = np.cumsum(np.random.randn(n_points) * 50)  # Random walk noise
        close = 50000 + trend + noise

        self.data = pd.DataFrame(
            {
                "open": close + np.random.randn(n_points) * 30,
                "high": close
                + abs(np.random.randn(n_points) * 80)
                + 20,  # Always above close
                "low": close
                - abs(np.random.randn(n_points) * 80)
                - 20,  # Always below close
                "close": close,
                "volume": np.random.uniform(500, 2000, n_points),
            },
            index=self.dates,
        )

    def load(self):
        """Return mock data."""
        return self.data


class TestCompleteDataFlow:
    """Test complete data flow from loading to features."""

    @pytest.fixture
    def raw_data(self):
        """Get raw price data."""
        loader = MockExchangeDataLoader()
        return loader.load()

    def test_data_loading(self, raw_data):
        """Test that data can be loaded."""
        assert isinstance(raw_data, pd.DataFrame)
        assert len(raw_data) > 0
        assert all(
            col in raw_data.columns
            for col in ["open", "high", "low", "close", "volume"]
        )

    def test_feature_engineering(self, raw_data):
        """Test feature engineering on loaded data."""
        config = FeatureConfig(
            volatility_window=20,
            ou_window=20,
            rolling_mean_window=20,
            use_log_returns=True,
            scaler_type="standard",
            save_scaler=False,
            scaler_path=Path("/tmp"),
            dropna_strategy="rolling",
            min_valid_rows=100,
        )

        engine = FeatureEngine(config)
        features = engine.fit_transform(raw_data)

        assert isinstance(features, pd.DataFrame)
        assert len(features) > 0
        assert len(features.columns) > len(
            raw_data.columns
        )  # Should have added features
        assert "log_ret" in features.columns
        assert "volatility_20" in features.columns
        assert "ou_score" in features.columns

    def test_environment_creation(self, raw_data):
        """Test environment creation with data and features."""
        # Generate features
        config = FeatureConfig(
            volatility_window=20,
            ou_window=20,
            rolling_mean_window=20,
            use_log_returns=True,
            scaler_type="standard",
            save_scaler=False,
            scaler_path=Path("/tmp"),
            dropna_strategy="rolling",
            min_valid_rows=100,
        )

        engine = FeatureEngine(config)
        features = engine.fit_transform(raw_data)

        # Align data to common timestamps (features may have NaN rows dropped)
        common_idx = raw_data.index.intersection(features.index)
        price_data = raw_data.loc[common_idx]
        features = features.loc[common_idx]

        # Create environment
        env_config = EnvironmentConfig(
            initial_capital=100000,
            max_position_size=0.25,
            max_drawdown=0.20,
            max_steps=100,
        )

        env = ConfigIntegratedTradingEnv(price_data, features, env_config)

        assert env is not None
        assert env.observation_space.shape[0] > 0

    def test_agent_environment_interaction(self, raw_data):
        """Test agent interacting with environment."""
        # Setup
        config = FeatureConfig(
            volatility_window=20,
            ou_window=20,
            rolling_mean_window=20,
            use_log_returns=True,
            scaler_type="standard",
            save_scaler=False,
            scaler_path=Path("/tmp"),
            dropna_strategy="rolling",
            min_valid_rows=100,
        )

        engine = FeatureEngine(config)
        features = engine.fit_transform(raw_data)

        common_idx = raw_data.index.intersection(features.index)
        price_data = raw_data.loc[common_idx]
        features = features.loc[common_idx]

        env_config = EnvironmentConfig(initial_capital=100000, max_steps=50)
        env = ConfigIntegratedTradingEnv(price_data, features, env_config)

        # Create agent
        agent_config = PPOConfig(
            state_dim=env.observation_space.shape[0],
            n_actions=env.action_space.n,
            hidden_dim=32,
            n_epochs=2,
            batch_size=16,
        )
        agent = PPOAgent(agent_config, device="cpu")

        # Interact for one episode (or up to 50 steps)
        obs, info = env.reset()
        done = False
        total_reward = 0
        steps = 0

        while not done and steps < 50:
            action, log_prob, value, hidden = agent.select_action(obs)
            next_obs, reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated

            agent.store_transition(obs, action, reward, log_prob, value, done)
            total_reward += reward
            obs = next_obs
            steps += 1

        assert steps > 0
        assert len(agent.states) == steps  # Buffer should have all transitions


class TestRiskManagementIntegration:
    """Test risk management integration with environment."""

    def test_circuit_breaker_in_environment(self):
        """Test that circuit breaker works in environment."""
        # Create simple data
        np.random.seed(42)
        dates = pd.date_range("2023-01-01", periods=200, freq="1H")
        close = 50000 + np.cumsum(np.random.randn(200) * 100)

        price_data = pd.DataFrame(
            {
                "open": close,
                "high": close + 50,
                "low": close - 50,
                "close": close,
                "volume": np.ones(200) * 1000,
            },
            index=dates,
        )

        features = pd.DataFrame(
            {
                "log_ret": np.zeros(200),
                "volatility_20": np.ones(200) * 0.02,
                "ou_score": np.zeros(200),
            },
            index=dates,
        )

        # Create environment with tight risk limits
        env_config = EnvironmentConfig(
            initial_capital=100000,
            max_position_size=0.25,
            max_drawdown=0.05,  # 5% drawdown limit (tight)
            max_steps=100,
        )

        env = ConfigIntegratedTradingEnv(price_data, features, env_config)
        obs, info = env.reset()

        # Simulate large losses
        circuit_breaker_triggered = False
        for _ in range(100):
            obs, reward, terminated, truncated, info = env.step(0)  # Keep selling

            if info.get("circuit_breaker", False):
                circuit_breaker_triggered = True
                break

            if terminated or truncated:
                break

        # Circuit breaker should have triggered due to drawdown
        # Note: This depends on the exact market simulation
        # We mainly verify the mechanism exists
        assert "risk_metrics" in info


class TestAdversarialTrainingIntegration:
    """Test adversarial training integration."""

    def test_end_to_end_training(self):
        """Test complete training loop with adversary."""
        # Create mock environment
        np.random.seed(42)
        dates = pd.date_range("2023-01-01", periods=300, freq="1H")
        close = 50000 + np.cumsum(np.random.randn(300) * 100)

        price_data = pd.DataFrame(
            {
                "open": close,
                "high": close + 50,
                "low": close - 50,
                "close": close,
                "volume": np.ones(300) * 1000,
            },
            index=dates,
        )

        # Generate features
        config = FeatureConfig(
            volatility_window=20,
            ou_window=20,
            rolling_mean_window=20,
            use_log_returns=True,
            scaler_type="standard",
            save_scaler=False,
            scaler_path=Path("/tmp"),
            dropna_strategy="rolling",
            min_valid_rows=50,
        )

        engine = FeatureEngine(config)
        features = engine.fit_transform(price_data)

        common_idx = price_data.index.intersection(features.index)
        price_data = price_data.loc[common_idx]
        features = features.loc[common_idx]

        # Create environment
        env_config = EnvironmentConfig(
            initial_capital=100000, max_position_size=0.25, max_steps=50
        )
        env = ConfigIntegratedTradingEnv(price_data, features, env_config)

        # Create adversarial trainer
        trader_config = PPOConfig(
            state_dim=env.observation_space.shape[0],
            n_actions=env.action_space.n,
            hidden_dim=32,
            n_epochs=2,
            batch_size=16,
        )

        adversary_config = PPOConfig(
            state_dim=env.observation_space.shape[0],
            n_actions=4,  # 4 perturbation strategies
            hidden_dim=32,
            n_epochs=2,
            batch_size=16,
        )

        training_config = AdversarialConfig(
            n_iterations=2,
            steps_per_iteration=64,
            trader_config=trader_config,
            adversary_config=adversary_config,
            adversary_start_iteration=0,  # Adversary active from start
            adversary_strength=0.1,
            log_frequency=1,
        )

        trainer = AdversarialTrainer(env, training_config, device="cpu")

        # Run training iterations manually
        for iteration in range(2):
            trainer.iteration = iteration

            # Collect trajectories
            metrics = trainer.collect_trajectories(64, use_adversary=True)

            # Train both agents
            trader_stats = trainer.train_trader(metrics["next_value"])
            adversary_stats = trainer.train_adversary(
                metrics.get("adversary_next_value", 0.0)
            )

            # Verify training happened
            assert "actor_loss" in trader_stats
            assert "adversary_loss" in adversary_stats
            assert "adversary_success_rate" in adversary_stats

            # Manually record history (mirrors what trainer.train() does)
            trainer.history["trader_rewards"].append(metrics["mean_reward"])
            trainer.history["trader_returns"].append(metrics["mean_return"])
            trainer.history["episodes"].append(len(metrics["episode_rewards"]))

        # Verify history was recorded
        assert len(trainer.history["trader_rewards"]) > 0


class TestDataIntegrity:
    """Test data integrity throughout the pipeline."""

    def test_no_data_leakage_in_features(self):
        """Test that feature engineering doesn't leak future data."""
        # Create data with clear train/test split
        np.random.seed(42)
        train_dates = pd.date_range("2023-01-01", periods=200, freq="1H")
        test_dates = pd.date_range("2023-01-09", periods=100, freq="1H")

        train_data = pd.DataFrame(
            {
                "open": np.random.randn(200) * 100 + 50000,
                "high": np.random.randn(200) * 100 + 50100,
                "low": np.random.randn(200) * 100 + 49900,
                "close": np.random.randn(200) * 100 + 50000,
                "volume": np.ones(200) * 1000,
            },
            index=train_dates,
        )

        test_data = pd.DataFrame(
            {
                "open": np.random.randn(100) * 100 + 51000,
                "high": np.random.randn(100) * 100 + 51100,
                "low": np.random.randn(100) * 100 + 50900,
                "close": np.random.randn(100) * 100 + 51000,
                "volume": np.ones(100) * 1000,
            },
            index=test_dates,
        )

        # Fit on train (compute scaler statistics from training data only)
        config = FeatureConfig(
            volatility_window=20,
            ou_window=20,
            rolling_mean_window=20,
            use_log_returns=True,
            scaler_type="standard",
            save_scaler=False,
            scaler_path=Path("/tmp"),
            dropna_strategy="rolling",
            min_valid_rows=50,
        )

        engine = FeatureEngine(config)
        train_features = engine.fit_transform(train_data)

        # Transform test (apply train statistics â€” no look-ahead)
        test_features = engine.transform(test_data)

        # Verify test features use train statistics
        assert len(test_features) == len(test_data) - 20  # Account for rolling window

    def test_environment_observation_shape_consistency(self):
        """Test that environment observation shape is consistent."""
        np.random.seed(42)
        dates = pd.date_range("2023-01-01", periods=200, freq="1H")
        close = 50000 + np.cumsum(np.random.randn(200) * 100)

        price_data = pd.DataFrame(
            {
                "open": close,
                "high": close + 50,
                "low": close - 50,
                "close": close,
                "volume": np.ones(200) * 1000,
            },
            index=dates,
        )

        features = pd.DataFrame(
            {
                "log_ret": np.random.randn(200) * 0.01,
                "volatility_20": np.ones(200) * 0.02,
                "ou_score": np.random.randn(200),
            },
            index=dates,
        )

        env_config = EnvironmentConfig(max_steps=50)
        env = ConfigIntegratedTradingEnv(price_data, features, env_config)

        obs, _ = env.reset()
        initial_shape = obs.shape  # Lock in expected observation shape

        for _ in range(10):
            obs, _, terminated, truncated, _ = env.step(1)
            if terminated or truncated:
                obs, _ = env.reset()
            assert obs.shape == initial_shape  # Shape must not change between steps


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
